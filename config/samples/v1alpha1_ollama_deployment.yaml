apiVersion: llm.geeper.io/v1alpha1
kind: LMDeployment
metadata:
  name: ollama-example
  namespace: default
spec:
  ollama:
    replicas: 1
    image: ollama/ollama
    imageTag: latest
    serviceType: ClusterIP
    servicePort: 11434

    models:
      - "llama2:7b"
      - "mistral:7b"
      - "codellama:7b"
  
  openwebui:
    enabled: true
    replicas: 1
    image: ghcr.io/open-webui/open-webui
    imageTag: main
    serviceType: ClusterIP
    servicePort: 8080
    ingressEnabled: true
    ingressHost: "ollama-webui.local"

