apiVersion: llm.geeper.io/v1alpha1
kind: LMDeployment
metadata:
  name: production-ollama
  namespace: ai-production
spec:
  ollama:
    replicas: 3
    image: ollama/ollama
    imageTag: latest
    service:
      type: LoadBalancer
      port: 11434
    resources:
      requests:
        cpu: "2"
        memory: "4Gi"
      limits:
        cpu: "8"
        memory: "16Gi"
    models:
      - "llama2:13b"
      - "codellama:34b"
      - "mistral:7b"
      - "phi:2.7b"
  
  openwebui:
    enabled: true
    replicas: 2
    image: ghcr.io/open-webui/open-webui
    imageTag: main
    service:
      type: ClusterIP
      port: 8080
    ingress:
      enabled: true
      host: "ai.company.com"
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
      limits:
        cpu: "2"
        memory: "2Gi"
